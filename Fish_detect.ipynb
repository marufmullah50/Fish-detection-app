{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkQlQTCUnz8q",
        "outputId": "7b94acb9-3b4c-45c0-ebef-a4b845f1fe39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "wQhQlbzrxmb5",
        "outputId": "c5d32bff-35a5-4821-ffd0-adb825ff2a28"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Fish_detection_project/BD_Freshwater_Fish_An_Image_Dataset_from_Bangladesh_for_AI_Powered_Automatic_Fish_Species_Classification_and_Detection_toward_Smart_Aquaculture/BD_Freshwater_Fish'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2159260723.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Verify dataset structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(classes)} species: {classes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Fish_detection_project/BD_Freshwater_Fish_An_Image_Dataset_from_Bangladesh_for_AI_Powered_Automatic_Fish_Species_Classification_and_Detection_toward_Smart_Aquaculture/BD_Freshwater_Fish'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "# Enable mixed precision training for T4 GPU\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# Directory where the dataset is stored\n",
        "train_dir = \"/content/drive/MyDrive/Fish_detection_project/BD_Freshwater_Fish_An_Image_Dataset_from_Bangladesh_for_AI_Powered_Automatic_Fish_Species_Classification_and_Detection_toward_Smart_Aquaculture/BD_Freshwater_Fish\"\n",
        "\n",
        "# Verify dataset structure\n",
        "classes = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "print(f\"Found {len(classes)} species: {classes}\")\n",
        "if len(classes) != 12:\n",
        "    print(\"Warning: Expected 12 species folders, please check the directory structure.\")\n",
        "\n",
        "# Define paths for train, validation, and test directories\n",
        "base_dir = \"/content/drive/MyDrive/Fish_detection_project/split_dataset\"\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "val_path = os.path.join(base_dir, 'validation')\n",
        "test_path = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for path in [train_path, val_path, test_path]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Function to split dataset\n",
        "def split_dataset(source_dir, train_path, val_path, test_path, train_size=0.7, val_size=0.15):\n",
        "    class_counts = {}\n",
        "    for class_name in classes:\n",
        "        os.makedirs(os.path.join(train_path, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_path, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_path, class_name), exist_ok=True)\n",
        "\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
        "        print(f\"Class {class_name}: {len(images)} images\")\n",
        "        class_counts[class_name] = len(images)\n",
        "\n",
        "        train_val_images, test_images = train_test_split(images, test_size=0.15, random_state=42)\n",
        "        train_images, val_images = train_test_split(train_val_images, test_size=val_size/(train_size + val_size), random_state=42)\n",
        "\n",
        "        for img in train_images:\n",
        "            shutil.copy(os.path.join(class_dir, img), os.path.join(train_path, class_name, img))\n",
        "        for img in val_images:\n",
        "            shutil.copy(os.path.join(class_dir, img), os.path.join(val_path, class_name, img))\n",
        "        for img in test_images:\n",
        "            shutil.copy(os.path.join(class_dir, img), os.path.join(test_path, class_name, img))\n",
        "        print(f\"Class {class_name}: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test\")\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "# Split the dataset and get class counts for weighting\n",
        "class_counts = split_dataset(train_dir, train_path, val_path, test_path)\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "total_samples = sum(class_counts.values())\n",
        "class_weights = {i: total_samples / (12 * class_counts[cls]) for i, cls in enumerate(classes)}\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Define image parameters\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128  # Your specified target size\n",
        "BATCH_SIZE = 16  # Your specified batch size, suitable for T4 GPU\n",
        "\n",
        "# Create ImageDataGenerators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,  # Your specified augmentation\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load and preprocess images\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Print class indices\n",
        "print(\"Class indices:\", train_generator.class_indices)\n",
        "\n",
        "# Manually download MobileNetV2 weights\n",
        "weights_url = \"https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\"\n",
        "weights_path = \"/content/mobilenet_v2_weights.h5\"\n",
        "\n",
        "print(\"Downloading MobileNetV2 weights...\")\n",
        "urllib.request.urlretrieve(weights_url, weights_path)\n",
        "\n",
        "# Build the model using MobileNetV2 with custom top\n",
        "base_model = MobileNetV2(weights=weights_path, include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(12, activation='softmax', dtype='float32')  # 12 species, float32 for mixed precision\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model with class weights\n",
        "try:\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=30,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        validation_steps=len(val_generator),\n",
        "        class_weight=class_weights\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\"Error during model training:\", e)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Fish_detection_project/fish_classification_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7DqL9LiV-WZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}